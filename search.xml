<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title></title>
    <url>%2F2019%2F04%2F28%2FTensorflow%E5%AE%9E%E6%88%98%20-%20MobileNet-V2%2F</url>
    <content type="text"><![CDATA[轻量化网络：MobileNet-V2 ResNet是：压缩”→“卷积提特征”→“扩张”，MobileNetV2则是Inverted residuals,即：“扩张”→“卷积提特征”→ “压缩” MobileNet-V1 最大的特点就是采用depth-wise separable convolution来减少运算量以及参数量，而在网络结构上，没有采用shortcut的方式。Resnet及Densenet等一系列采用shortcut的网络的成功，表明了shortcut是个非常好的东西，于是MobileNet-V2就将这个好东西拿来用。 拿来主义，最重要的就是要结合自身的特点，MobileNet的特点就是depth-wise separable convolution，但是直接把depth-wise separable convolution应用到 residual block中，会碰到如下问题： 1.DWConv layer层提取得到的特征受限于输入的通道数，若是采用以往的residual block，先“压缩”，再卷积提特征，那么DWConv layer可提取得特征就太少了，因此一开始不“压缩”，MobileNetV2反其道而行，一开始先“扩张”，本文实验“扩张”倍数为6。 通常residual block里面是 “压缩”→“卷积提特征”→“扩张”，MobileNetV2就变成了 “扩张”→“卷积提特征”→ “压缩”，因此称为Inverted residuals 2.当采用“扩张”→“卷积提特征”→ “压缩”时，在“压缩”之后会碰到一个问题，那就是Relu会破坏特征。为什么这里的Relu会破坏特征呢？这得从Relu的性质说起，Relu对于负的输入，输出全为零；而本来特征就已经被“压缩”，再经过Relu的话，又要“损失”一部分特征，因此这里不采用Relu，实验结果表明这样做是正确的，这就称为Linear bottlenecks inverted residuals结构一个bottleneck11 conv2d ,Relu6 扩张33 dwise s=s, Relu6 卷积linear 1*1 conv2d 压缩 除了最后的avgpool，中间没有使用pool进行下采样 和MobileNet V1相比，MobileNet V2主要的改进有两点：1、Linear Bottlenecks。也就是去掉了小维度输出层后面的非线性激活层，目的是为了保证模型的表达能力。2、Inverted Residual block。该结构和传统residual block中维度先缩减再扩增正好相反，因此shotcut也就变成了连接的是维度缩减后的feature map 非线性激活层 relubottleneck的输出不接非线性激活层，所以是linear]]></content>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2019%2F04%2F28%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
  </entry>
  <entry>
    <title><![CDATA[Tensorflow实战 - 模型持久化]]></title>
    <url>%2F2018%2F05%2F09%2FTensorflow%E5%AE%9E%E6%88%98%20-%20%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%BF%9D%E5%AD%98%E4%B8%8E%E6%81%A2%E5%A4%8D%2F</url>
    <content type="text"><![CDATA[持久化代码实现tf.train.Saver12saver = tf.train.Saver()saver.save( ... ) Tensorflow模型保存到ckpt文件中，生成三个文件model.ckpt.meta，保存计算图的结构model.ckpt，保存TF程序中每一个变量的取值checkpoint，保存了一个目录下所有的模型文件列表]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[大数据]]></title>
    <url>%2F2018%2F05%2F07%2F%E5%A4%A7%E6%95%B0%E6%8D%AE%2F</url>
    <content type="text"></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>大数据</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Tensorflow实战 - 模型持久化]]></title>
    <url>%2F2018%2F04%2F03%2FTensorflow%E5%AE%9E%E6%88%98%20-%20%E6%A8%A1%E5%9E%8B%E6%8C%81%E4%B9%85%E5%8C%96%2F</url>
    <content type="text"><![CDATA[持久化代码实现tf.train.Saver12saver = tf.train.Saver()saver.save( ... ) 模型的保存12345678910import tensorflow as tfckpt_dir = r'...\model.ckpt'v1 = tf.Variable(tf.constant(1.0, shape=[1], name="v1"))v2 = tf.Variable(tf.constant(2.0, shape=[1], name="v2"))result = v1 + v2 init = tf.global_variables_initializer()saver = tf.train.Saver()with tf.Session() as sess: sess.run(init) saver.save(sess,ckpt_dir) tf.train.Saver()使用的时候必须在之前是有变量存在的，上述代码中定义了v1,v2两个变量，保存在模型文件中。 代码产生四个文件 checkpoint文件保存了一个录下多有的模型文件列表 model.ckpt.meta保存了TensorFlow计算图的结构信息 model.ckpt保存每个变量的取值，此处文件名的写入方式会因不同参数的设置而不同，但加载restore时的文件路径名是以checkpoint文件中的“model_checkpoint_path”值决定的。 模型的恢复恢复时特别注意checkpoints文件中的“model_checkpoint_path”值，一定与meta、ckpt路径对应起来123456789import tensorflow as tf ckpt_dir = r'...\model.ckpt'v1 = tf.Variable(tf.constant(1.0, shape=[1]), name="v1") v2 = tf.Variable(tf.constant(2.0, shape=[1]), name="v2") result = v1 + v2 saver = tf.train.Saver() with tf.Session() as sess: saver.restore(sess, ckpt_dir) print(sess.run(result)) 上述恢复时重复了计算图上的运算 直接加载持久化的图不重复计算图的计算12345678910111213141516import tensorflow as tf checkpoint = r'...\ckpts' #checkpoint路径ckpt_dir = r'...\model.ckpt'meta_dir = r'...\ckpts\model.ckpt.meta'graph = tf.Graph()sess_conf = tf.ConfigProto()sess = tf.Session(graph=graph, config=sess_conf)with graph.as_default(): saver = tf.train.import_meta_graph(model_meta) saver.restore(source_sess, ckpts) # or # latest_checkpoint = tf.train.latest_checkpoint(model_checkpoints) # saver.restore(source_sess, latest_checkpoint) tensor = graph.get_tensor_by_name('tensorname') print(sess.run(tensor)) 从训练好的模型中的保存部分参数到新模型每次都重新训练新的模型，是一件十分耗时费力的事情，在我们的项目中有用到tensorflow-finetune的知识，就是取出中间某些层的权值，去掉最后一层FC，那么就需要对原模型部分参数保存，首先还是一样直接加载持久化的图按照tf.train.Saver源码中关于var_list的解释：var_list specifies the variables that will be saved and restored. It can be passed as a dict or a list,可以选择性的保存参数12345678910111213141516171819202122232425import tensorflow as tf checkpoint = r'...\ckpts' #checkpoint路径ckpt_dir = r'...\ckpts\model.ckpt'meta_dir = r'...\ckpts\model.ckpt.meta'# 包含部分参数的ckptpart_ckpt = r'...\ckptsp\model.ckpt'sourceGraph = tf.Graph()sess_conf = tf.ConfigProto()sess = tf.Session(graph=graph, config=sess_conf)with sourceGraph.as_default(): saver = tf.train.import_meta_graph(model_meta) saver.restore(source_sess, ckpts) # 获得所有训练的变量名称 variables_names = [v.name for v in tf.trainable_variables()] tensorList = [] for name in variables_names: if 'name(last_fc)' not in name: tensorList.append(sourceGraph.get_tensor_by_name(name)) # tensorList中保存了去掉最后一层fc的其他层权值 # 重新构建一个save1 saver1 = tf.train.Saver(tensorList) saver1.save(source_sess, part_ckpt + '/model.ckpt', global_step='...') 包含部分参数的模型恢复]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Tensorflow高级API - TensorBoard计算加速]]></title>
    <url>%2F2018%2F03%2F30%2FTensorflow%E9%AB%98%E7%BA%A7API%2F</url>
    <content type="text"><![CDATA[对Dataset中的元素做变换Dataset支持一类特殊的操作：Transformation。一个Dataset通过Transformation变成一个新的Dataset。通常我们可以通过Transformation完成数据变换，打乱，组成batch，生成epoch等一系列操作。 常用的Transformation有： map batch shuffle repeat (1) mapmap接收一个函数，Dataset中的每个元素都会被当作这个函数的输入，并将函数返回值作为新的Dataset。 (2) batchbatch就是将多个元素组合成batch，如下面的程序将dataset中的每个元素组成了大小为32的batch：1dataset = dataset.batch(32) (3) shuffleshuffle的功能为打乱dataset中的元素，它有一个参数buffersize，表示打乱时使用的buffer的大小 (4) repeatrepeat的功能就是将整个序列重复多次，主要用来处理机器学习中的epoch，假设原先的数据是一个epoch，使用repeat(5)就可以将之变成5个epoch]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python学习 - 基础]]></title>
    <url>%2F2018%2F03%2F27%2FPython%E5%AD%A6%E4%B9%A0%2FPython%E5%AD%A6%E4%B9%A0-%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[tf.placeholder(dtype, shape=None, name=None) placeholder，占位符，在tensorflow中类似于函数参数，运行时必须传入值。 dtype：数据类型。常用的是tf.float32,tf.float64等数值类型。shape：数据形状。默认是None，就是一维值，也可以是多维，比如[2,3], [None, 3]表示列是3，行不定。name：名称。]]></content>
      <categories>
        <category>Python基础</category>
      </categories>
      <tags>
        <tag>Python基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python学习 - 文件目录处理]]></title>
    <url>%2F2018%2F03%2F27%2FPython%E5%AD%A6%E4%B9%A0%2FPython%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[OS模块Python os模块包含普遍的操作系统功能。如果你希望你的程序能够与平台无关的话，这个模块是尤为重要的。在自动化测试中，经常需要查找操作文件，比如说查找配置文件（从而读取配置文件的信息），查找测试报告（从而发送测试报告邮件），经常要对大量文件和大量路径进行操作，这就依赖于os模块 1.当前路径及路径下的文件os.getcwd()：查看当前所在路径。os.listdir(path):列举目录下的所有文件。返回的是列表类型。 2.绝对路径os.path.abspath(path):返回path的绝对路径。 3.查看路径的文件夹部分和文件名部分os.path.split(path):将路径分解为(文件夹,文件名)，返回的是元组类型。可以看出，若路径字符串最后一个字符是\,则只有文件夹部分有值；若路径字符串中均无\,则只有文件名部分有值。若路径字符串有\，且不在最后，则文件夹和文件名均有值。且返回的文件夹的结果不包含.os.path.join(path1,path2,…):将path进行组合，若其中有绝对路径，则之前的path将被删除。os.path.dirname(path):返回path中的文件夹部分，结果不包含’\’os.path.basename(path):返回path中的文件名。 4.查看文件时间os.path.getmtime(path):文件或文件夹的最后修改时间，从新纪元到访问时的秒数。os.path.getatime(path):文件或文件夹的最后访问时间，从新纪元到访问时的秒数。os.path.getctime(path):文件或文件夹的创建时间，从新纪元到访问时的秒数。 sys对于模块和自己写的程序不在同一个目录下，可以把模块的路径通过sys.path.append(路径)添加到程序中。12import syssys.path.append('引用模块的地址')]]></content>
      <categories>
        <category>Python基础</category>
      </categories>
      <tags>
        <tag>Python基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Tensorflow实战 - TensorBoard计算加速]]></title>
    <url>%2F2018%2F03%2F26%2FTensorflow%E5%AE%9E%E6%88%98%20-%20Tensorflow%E8%AE%A1%E7%AE%97%E5%8A%A0%E9%80%9F%2F</url>
    <content type="text"><![CDATA[Tensorflow计算加速Tensorflow使用GPUtf.ConfigProto1234567tf.ConfigProto一般用在创建session的时候。用来对session进行参数配置with tf.Session(config = tf.ConfigProto(...),...)#tf.ConfigProto()的参数log_device_placement=True : 是否打印设备分配日志allow_soft_placement=True ： 如果你指定的设备不存在，允许TF自动分配设备tf.ConfigProto(log_device_placement=True,allow_soft_placement=True) 深度学习训练并行模式 异步模式 同步模式 多GPU并行分布式Tensorflow123456789tf.train.ClusterSpec(&#123; "worker":[ "tf.worker0:2222", "tf.worker1:2222", "tf.worker2:2222" ],[ "ps":[ "" ]&#125;)]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Tensorflow实战 - TensorBoard可视化]]></title>
    <url>%2F2018%2F03%2F26%2FTensorflow%E5%AE%9E%E6%88%98%20-%20TensorBoard%E5%8F%AF%E8%A7%86%E5%8C%96%2F</url>
    <content type="text"><![CDATA[TensorBoard简介通过Tensorflow程序运行过程中的输出的日志文件可视化Tensorflow程序的运行状态 TensorBoard日志输出123456import tensorflow as tfinput1 = tf.constant([1.0,2.0,3.0], name="input1")input2 = tf.Variable(tf.random_uniform([3]),name="input2")output = tf.add_n([input1,input2],name="add")writer = tf.summary.FileWriter("F://log",tf.get_default_graph())writer.close() TensorBoard服务启动1tensorboard --logdir=F://log]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Tensorflow实战 - 循环神经网络]]></title>
    <url>%2F2018%2F03%2F22%2FTensorflow%E5%AE%9E%E6%88%98%20-%20%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%2F</url>
    <content type="text"><![CDATA[循环神经网络(RNN)长短时记忆网络结构(LTSM)LSTM单元结构示意图 遗忘门 输入门 输出门 循环神经网络的变种双向循环神经网络深层循环神经网络循环神经网络的dropout循环神经网络样例应用自然语言建模数据预处理ptb_raw_data 读取PTB原始数据，并将单词转化为单词IDptb_iterator 截断并组织成batch 时序序列预测使用TFLean自定义模型tf.contrib.learn 预测正弦函数]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Tensorflow实战 - 多线程输入数据处理框架]]></title>
    <url>%2F2018%2F03%2F21%2FTensorflow%E5%AE%9E%E6%88%98%20-%20%E5%A4%9A%E7%BA%BF%E7%A8%8B%E8%BE%93%E5%85%A5%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%A1%86%E6%9E%B6%2F</url>
    <content type="text"><![CDATA[多线程输入数据处理框架为了避免图像预处理成为神经网络模型训练效率的瓶颈。 经典输入数据处理流程图123456op=&gt;operation: 指定原始数据的文件列表op2=&gt;operation: 创建文件列表队列op3=&gt;operation: 从文件中读取数据op4=&gt;operation: 数据预处理op5=&gt;operation: 整理成Batch作为神经网络输入op-&gt;op2-&gt;op3-&gt;op4-&gt;op5 队列与多线程队列 FIFOQueue先进先出队列 RandomShuffleQueue随机队列 多线程 tf.Coordinator协同多线程一起停止123@should_stop@request_stop@join tf.QueueRunner启动多个线程来操作同一个队列 输入文件队列 tf.train.match_filenames_once函数来获取符合一个正则表达式的所有文件 tf.train.string_input_producer函数管理文件列表123456789101112131415161718192021222324252627# 样例代码import tensorflow as tf# 使用tf.train.match_filenames_once函数获取文件列表files = tf.train.match_filenames_once("Records/data.tfrecords-*")# 通过tf.train.string_input_producer函数创建输入队列，输入队列的文件列表为tf.train.match_filenames_once函数获取的文件列表，shuffle参数设置为False来避免随机打乱读取文件的顺序。一般情况下设置为Truefilename_queue = tf.train.string_input_producer(files, shuffle=False) # 读取并解析一个样本reader = tf.TFRecordReader()_, serialized_example = reader.read(filename_queue)features = tf.parse_single_example( serialized_example, features=&#123; 'i': tf.FixedLenFeature([], tf.int64), 'j': tf.FixedLenFeature([], tf.int64), &#125;)with tf.Session() as sess:# 使用tf.train.match_filenames_once函数时需要初始化一些变量 tf.global_variables_initializer().run() print sess.run(files)# 声明tf.train.Coordinator类来协同不同线程，并启动线程 coord = tf.train.Coordinator() threads = tf.train.start_queue_runners(sess=sess, coord=coord)# 多次执行获取数据的操作 for i in range(6): print sess.run([features['i'], features['j']]) coord.request_stop() coord.join(threads) 组合训练数据(batching)将多个输入样例组织成一个batch可以提高模型训练的效率，所以在得到单个样例的预处理结果之后，还需要将它们组织成batch，然后再提供给神经网络的输入层 tf.train.batch tf.train.shuffle_batch1234567# [example ,label]参数给出了需要组合的元素，一般example和label分别代表训练样本和这个样本对应的正确标签。batch_size参数给出了每个batch中样例的个数。capacity给出了队列的最大容量。队列长度 = 容量，TF将暂停入队，等待元素出队。元素个数 &lt; 容量，TF将重新启动入队example_batch, label_batch = tf.train.batch([example , label],batch_size = batch_size , capacity = capacity)# min_after_dequeue参数限制了出队时队列中元素的最少个数。当队列中元素太少时，随机打乱样例顺序的作用就不大了example_batch, label_batch = tf.train.shuffle_batch([example , label],batch_size = batch_size , capacity = capacity , min_after_dequeue = 30)# 并行化处理输入数据的方法指定num_thread参数 &gt; 1，多个线程会同时读取一个文件中的不同样例并进行预处理。多线程处理不同文件，使用tf.train.shuffle_batch_join函数 输入数据处理框架]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Tensorflow实战 - 图像数据处理]]></title>
    <url>%2F2018%2F03%2F20%2FTensorflow%E5%AE%9E%E6%88%98%20-%20%E5%9B%BE%E5%83%8F%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%2F</url>
    <content type="text"><![CDATA[TFRecord输入数据格式TFRecord格式介绍tf.train.Example Protocol Buffer的格式存储123456789101112131415message Example &#123; Feature features = 1;&#125;;message Feature &#123; map&lt;String, Feature&gt; features = 1;&#125;;message Feature &#123; oneof kind &#123; BytesList bytes_list = 1; FloatList float_list = 2; Int64List int64_list = 3; &#125;&#125;; 图像数据处理使用图像预处理的方法可以减小无关因素对图像识别模型效果的影响 Tensorflow图像处理函数图像编码处理Tensorflow处理图像时，将图像视为矩阵，然而图像在存储时并不直接记录这些矩阵中的数字，而是记录经过压缩编码后的结果。所以要将一张图片还原成一个三维矩阵，需要解码的过程。TF提供了对jpeg和png格式图像的编码/解码函数。 在读入图像时，要使用解码函数才能得到三维矩阵；在保存图像时，需要使用编码函数才能将三维矩阵转换为需要的编码格式。123456789101112131415161718# 读入图像的原始数据 image_raw_data = tf.gfile.FastGFile("F:/input.jpeg", 'rb').read() # 将图像使用jpeg的格式解码从而得到图像对应的三维矩阵，解码之后的结果为一个张量 img_data = tf.image.decode_jpeg(image_raw_data) # 将数据的类型转换为8位无符号整型 img_data = tf.image.convert_image_dtype(img_data, dtype=tf.uint8) # 将表示一张图片的三维矩阵重新按照png格式编码并存入文件中。 encoder_png_image = tf.image.encode_png(img_data) with tf.gfile.GFile("F:/output.png", 'wb') as f: f.write(encoder_png_image.eval()) # 按照jpeg格式编码，保存 encoder_jpeg_image = tf.image.encode_png(img_data) with tf.gfile.GFile("F:/output.jpeg", 'wb') as f: f.write(encoder_jpeg_image.eval()) 图像大小调整神经网络输入节点的个数是固定的，所以在将图像的像素作为输入提供给神经网络之前，需要将图像的大小统一。1234tf.image.resize_images(param1,param2,param3，method)@param1 原始图像@param2、@param3 调整后图像的大小 @method 调整图像大小的算法 tf.image.resize_images函数的method参数取值对应算法| method取值 | 图像大小调整算法 || ——– | —–: || 0 | 双线性插值法(Bilinear interpolation) || 1 | 最近邻居法(Nearest neighbor interpolation) || 2 | 双三次插值法(Bicubic interpolation) || 3 | 面积插值法(Area interpolation) | 图像的裁剪和填充12345678# 裁剪或者填充图像中间区域tf.image.resize_image_with_crop_or_pad(param1,param2,param3)@param1 原始图像@param2、@param3 调整后图像的大小 # 裁剪或者填充给定区域的图像tf.image.crop_to_bounding_box(param2 * param3 &lt; 原始图像尺寸)tf.image.pad_to_bounding_box 图像翻转1234567891011121314# 图像上下翻转flipped = tf.image.flip_up_down(img_data)# 图像左右翻转flipped = tf.image.flip_left_right(img_data)# 图像沿对角线翻转transposed = tf.image.transpose_image(img_data)# 以一定概率上下翻转flipped = tf.image.random_flip_up_down(img_data)# 以一定概率左右翻转flipped = tf.image.random_flip_left_right(img_data) 图像色彩调整1234567891011121314151617181920212223# 将图像的亮度+(-)aadjusted = tf.image.adjust_brightness(img_data, +(-)a)# 在[-max_data, max_data]的范围随机调整图像的亮度adjusted = tf.image.random_brightness(image, max_delta)# 将图像的对比度+(-)aadjusted = tf.image.adjust_contrast(img_data, +(-)a)# 在[lower, upper]的范围内随机调整图的对比度adjusted = tf.image.random_contrast(image, lower, upper)# 调整图像的色相adjusted = tf.image.adjust_hue(ima_data , a)# 在[-max_delta , max_delta]的范围内随机调整图像的色相# max_delta的取值在[0, 0.5]之间adjusted = tf.image.random_hue(image , max_delta)# 调整图像的饱和度adjusted = tf.image.adjust_saturation(img_data , a)adjusted = tf.image.random_saturation(image , lower , upper)# 图像标准化adjusted = tf.image.per_image_whitening(img_data)调整亮度均值为0，方差为1 处理标注框12345# 加入标注框tf.image.draw_bounding_boxes#随机截取图像tf.image.sample_distored_bounding_box]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Tensorflow实战]]></title>
    <url>%2F2018%2F03%2F16%2FTensorflow%E5%AE%9E%E6%88%98%2F</url>
    <content type="text"><![CDATA[卷积神经网络卷积神经网络的结构 输入层 卷积层 池化层 全连接层 Softmax层 卷积层 过滤器 内核 池化层池化层使用的过滤器只影响一个深度上的节点 最大池化层 1pool 平均池化层 其他]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Tensorflow实战 - 卷积神经网络]]></title>
    <url>%2F2018%2F03%2F16%2FTensorflow%E5%AE%9E%E6%88%98%20-%20%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%2F</url>
    <content type="text"><![CDATA[经典卷积神经网络模型LeNet5模型 第一层，卷积层 第二层，池化层 第三层，卷积层 第四层，池化层 第五层，全连接层 第六层，全连接层 第七层，全连接层 1输入层 -&gt; (卷积层 +-&gt; 池化层？) +-&gt; 全连接层 + Inception-v3模型Inception结构将不同的卷积层通过并联的方式结合到一起 Inception-v3模型TensorFlow-Slim工具12net = slim.conv2d(输入节点矩阵, 当前卷积层过滤器的深度, 过滤器的尺寸)可选参数: 过滤器移动步长（stride）、是否使用全0填充（padding="SAME"/"VALID"）、激活函数选择、变量的命名空间 计算 矩阵大小的计算 参数 连接数 迁移学习将一个问题上训练好的模型通过简单的调整使其适用于一个新的问题。通过迁移学习，可以使用少量的训练数据在短时间内训练出效果还不错的神经网络。]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello,Hexo]]></title>
    <url>%2F2018%2F03%2F16%2FHello-Hexo%2F</url>
    <content type="text"></content>
      <categories>
        <category>搭建博客</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>github</tag>
        <tag>npm</tag>
        <tag>基础</tag>
      </tags>
  </entry>
</search>
